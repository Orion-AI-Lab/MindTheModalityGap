{
    "id": "patch",
    "num_epochs": 1,
    "shuffle": true,
    "eval_frequency": 5,
    "train_batch_size": 128,
    "test_batch_size": 256,
    "val_batch_size": 256,
    "optimizer": {
        "_target_": "torch.optim.AdamW",
        "lr": 1e-5,
        "weight_decay": 0.5
    },
    "lr_scheduler": {
        "_target_": "torch.optim.lr_scheduler.CosineAnnealingLR",
        "base_lr": 1e-5,
        "warmup_length": 200
    },
    "alphas": [
        0.0,
        0.5,
        1.0
    ]
}